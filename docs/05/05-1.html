<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Do it! 쉽게 배우는 R 텍스트 마이닝 - 05 의미망 분석:   어떤 맥락에서 단어를 썼을까?</title>
    <meta charset="utf-8" />
    <meta name="author" content="김영우" />
    <script src="libs/header-attrs/header-attrs.js"></script>
    <link href="libs/remark-css/default.css" rel="stylesheet" />
    <link href="libs/tile-view/tile-view.css" rel="stylesheet" />
    <script src="libs/tile-view/tile-view.js"></script>
    <link rel="stylesheet" href="../css/custom.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">







class: title0

Do it! 쉽게 배우는 R 텍스트 마이닝

---



&lt;br&gt;

.pull-left[
&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;
&lt;img src="https://raw.githubusercontent.com/youngwoos/Doit_textmining/main/cover.png" width="70%" height="70%" /&gt;
]

.pull-right[

&lt;br&gt;
&lt;br&gt;
&lt;br&gt;

&lt;svg viewBox="0 0 496 512" xmlns="http://www.w3.org/2000/svg" style="height:1em;fill:currentColor;position:relative;display:inline-block;top:.1em;"&gt;  [ comment ]  &lt;path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"&gt;&lt;/path&gt;&lt;/svg&gt; [github.com/youngwoos/Doit_textmining](https://github.com/youngwoos/Doit_textmining)

&lt;svg viewBox="0 0 448 512" xmlns="http://www.w3.org/2000/svg" style="height:1em;fill:currentColor;position:relative;display:inline-block;top:.1em;"&gt;  [ comment ]  &lt;path d="M400 32H48A48 48 0 0 0 0 80v352a48 48 0 0 0 48 48h137.25V327.69h-63V256h63v-54.64c0-62.15 37-96.48 93.67-96.48 27.14 0 55.52 4.84 55.52 4.84v61h-31.27c-30.81 0-40.42 19.12-40.42 38.73V256h68.78l-11 71.69h-57.78V480H400a48 48 0 0 0 48-48V80a48 48 0 0 0-48-48z"&gt;&lt;/path&gt;&lt;/svg&gt; [facebook.com/groups/datacommunity](https://facebook.com/groups/datacommunity)

- [네이버책](https://book.naver.com/bookdb/book_detail.nhn?bid=17891971)
  - [yes24](http://bit.ly/3oUuJOB)
  - [알라딘](http://bit.ly/3oXOSDn)
  - [교보문고](https://bit.ly/2LtNOcB)
]

---

class: title0

05 의미망 분석: &lt;br&gt; 어떤 맥락에서 단어를 썼을까?

---

class: title0-2

We'll make

&lt;br-back-20&gt;

&lt;img src="../Image/05/05_2_6.png" width="70%" height="70%" /&gt;

---

class: title0-2

We'll make

&lt;br-back-20&gt;

&lt;img src="../Image/05/05_3_2.png" width="70%" height="70%" /&gt;

---

class: title0-2

and

&lt;br-back-40&gt;

&lt;img src="../Image/05/05_4_2.png" width="65%" height="65%" /&gt;

---

&lt;br&gt;

.large2[.font-jua[목차]]

.large[.font-jua[05-1 동시 출현 단어 분석 - Co-occurrence analysis]]([link](#05-1))

.large[.font-jua[05-2 동시 출현 네트워크 - Co-occurrence network]]([link](#05-2))

.large[.font-jua[05-3 단어 간 상관 분석 - Phi coefficient]]([link](#05-3))

.large[.font-jua[05-4 연이어 사용된 단어쌍 분석 - n-gram]]([link](#05-4))


---


name: 05-1
class: title1

05-1 동시 출현 단어 분석 - Co-occurrence analysis

---

- 단어 빈도 중심 분석의 한계: 단어가 사용된 맥락을 알 수 없다
- 텍스트의 맥락을 이해하려면
  - 단어의 관계를 이용해 의미망(semantic network) 만들기
  - 단어들이 어떤 관계를 가지고 있는지 살펴보기

--


##### 동시 출현 단어 분석(Co-occurrence analysis)

- 단어 간의 *관계*를 살펴보는 분석 방법
   - '손-장갑', '머리-모자' 처럼 관계가 있는 단어 파악

---
 
#### 기본적인 전처리

---

&lt;!-- 영화 기생충 기사 댓글을 불러와 분석에 적합하게 전처리를 하겠습니다. 여기서도 같은 내용의 댓글을 구분할 수 있도록 `row_number()`를 이용해 고유값 `id`를 추가하겠습니다. --&gt;

&lt;!-- &lt;!-- 원고 코드 --&gt; --&gt;
&lt;!-- ```{r eval=F} --&gt;
&lt;!-- # 기생충 기사 댓글 불러오기 --&gt;
&lt;!-- library(readr) --&gt;
&lt;!-- raw_news_comment &lt;- read_csv("news_comment_parasite.csv") --&gt;

&lt;!-- # 전처리 --&gt;
&lt;!-- library(dplyr) --&gt;
&lt;!-- library(stringr) --&gt;
&lt;!-- library(textclean) --&gt;

&lt;!-- news_comment &lt;- raw_news_comment %&gt;% --&gt;
&lt;!--   select(reply) %&gt;% --&gt;
&lt;!--   mutate(reply = str_replace_all(reply, "[^가-힣]", " "), --&gt;
&lt;!--          reply = str_squish(reply),          --&gt;
&lt;!--          id = row_number()) --&gt;
&lt;!-- ``` --&gt;

&lt;!-- &lt;!-- 실행 코드 --&gt; --&gt;
&lt;!-- ```{r echo=F} --&gt;
&lt;!-- library(readr) --&gt;
&lt;!-- library(dplyr) --&gt;
&lt;!-- library(stringr) --&gt;
&lt;!-- library(textclean) --&gt;

&lt;!-- # 기생충 기사 댓글 불러오기 --&gt;
&lt;!-- raw_news_comment &lt;- read_csv(here::here("files/news_comment_parasite.csv")) --&gt;

&lt;!-- news_comment &lt;- raw_news_comment %&gt;% --&gt;
&lt;!--   select(reply) %&gt;% --&gt;
&lt;!--   mutate(reply = str_replace_all(reply, "[^가-힣]", " "), --&gt;
&lt;!--          reply = str_squish(reply), --&gt;
&lt;!--          id = row_number()) --&gt;

&lt;!-- ``` --&gt;


&lt;!-- ### 5.1.2 토큰화하기 --&gt;

&lt;!-- 동시 출현 단어 분석은 단어가 사용된 맥락을 이해하는 것이므로 명사 뿐 아니라 형용사와 동사를 함께 살펴봐야 합니다. 텍스트에 사용된 형용사와 동사에 따라 명사의 의미가 달라지기 때문입니다. --&gt;

&lt;!-- #### 1. 형태소 분석기를 이용해 토큰화하기 --&gt;

&lt;!-- 지금까지는 토큰화 할 때 명사를 추출하도록 `unnest_tokens()`의 `token`에 `extractNoun()`을 이용했습니다. 하지만 여기서는 다른 품사들도 함께 추출해야 하므로 `SimplePos22()`를 이용해야 합니다. `SimplePos22()`는 문장을 구성하는 단어를 22개의 품사로 구분해 줍니다. --&gt;

&lt;!-- ```{r} --&gt;
&lt;!-- library(tidytext) --&gt;
&lt;!-- library(KoNLP) --&gt;

&lt;!-- comment_pos &lt;- news_comment %&gt;% --&gt;
&lt;!--   unnest_tokens(input = reply, --&gt;
&lt;!--                 output = word, --&gt;
&lt;!--                 token = SimplePos22, --&gt;
&lt;!--                 drop = F) --&gt;

&lt;!-- comment_pos %&gt;%  --&gt;
&lt;!--   select(word, reply) --&gt;
&lt;!-- ``` --&gt;

&lt;!-- &gt; [편집] 출력 줄맞춤 --&gt;

&lt;!-- &lt;br&gt; --&gt;

&lt;!-- &gt; [참고] `SimplePos22()`가 품사를 어떻게 구분하는지 궁금하다면 접속해 보세요. --&gt;

&lt;!-- &gt; [- github.com/haven-jeon/KoNLP/blob/master/etcs/KoNLP-API.md](github.com/haven-jeon/KoNLP/blob/master/etcs/KoNLP-API.md) --&gt;


&lt;!-- 출력 결과를 보면 문장을 구성하는 각 단어 뒤에 `"/nc"`, `"/pv"`와 같이 품사를 나타내는 태그(Tag, 꼬리표)가 붙어있습니다. 태그를 이용하면 원하는 품사의 단어를 추출할 수 있습니다. --&gt;

&lt;!-- #### 품사 분리하여 행 구성하기 - `separate_rows()` --&gt;

&lt;!-- `comment_pos`의 `word`는 여러 품사가 결합된 형태로 되어있습니다. 원하는 품사만 추출하기 쉽도록 `tidyr`패키지의 `separate_rows()`를 이용해 한 행이 한 품사의 단어로 구성되도록 만들겠습니다. `separate_rows()`는 텍스트를 `sep`에 입력한 정규표현식에 따라 여러 행으로 나누는 기능을 합니다. 다음 코드는 `sep`에 `"[+]"`를 입력했으므로 `"+"`가 등장할 때마다 행을 나눕니다. --&gt;


&lt;!-- ```{r} --&gt;
&lt;!-- # 품사별로 행 분리 --&gt;
&lt;!-- library(tidyr) --&gt;
&lt;!-- comment_pos &lt;- comment_pos %&gt;% --&gt;
&lt;!--   separate_rows(word, sep = "[+]") --&gt;

&lt;!-- comment_pos %&gt;%  --&gt;
&lt;!--   select(word, reply) --&gt;
&lt;!-- ``` --&gt;

&lt;!-- &gt; [편집] 출력 줄맞춤 --&gt;

&lt;!-- #### 2. 품사 추출하기 --&gt;

&lt;!-- #### (1) 명사 추출하기 --&gt;

&lt;!-- 이제 분석에 사용할 품사의 단어를 추출할 차례입니다. 우선 명사를 먼저 추출하겠습니다. 단어 뒤에 붙어있는 태그 `"/n"`을 이용하면 명사를 추출할 수 있습니다. 우선 `str_detect()`를 이용해 `"/n"`이 붙어있는 단어를 추출합니다. 그런 다음 `str_remove()`를 이용해 태그를 제거합니다. `str_remove()`에 입력한 `"/.*$"`는 "/로 시작하는 모든 문자"를 의미하는 정규표현식이므로 태그 부분만 제거하게 됩니다. --&gt;


&lt;!-- ```{r} --&gt;
&lt;!-- # 명사 추출하기 --&gt;
&lt;!-- noun &lt;- comment_pos %&gt;% --&gt;
&lt;!--   filter(str_detect(word, "/n")) %&gt;% --&gt;
&lt;!--   mutate(word = str_remove(word, "/.*$")) --&gt;

&lt;!-- noun %&gt;% --&gt;
&lt;!--   select(word, reply) --&gt;
&lt;!-- ``` --&gt;

&lt;!-- 이제 `count()`를 이용하면 댓글에서 어떤 명사가 가장 많이 사용됐는지 쉽게 알아볼 수 있습니다. --&gt;

&lt;!-- ```{r} --&gt;
&lt;!-- noun %&gt;% --&gt;
&lt;!--   count(word, sort = T) --&gt;
&lt;!-- ``` --&gt;

&lt;!-- #### (2) 동사, 형용사 추출하기 --&gt;

&lt;!-- 이번에는 동사와 형용사를 추출하겠습니다. 동사에는 `"/pv"`, 형용사에는 `"/pa"`라는 태그가 붙어 있으므로 `str_detect()`에 `"/pv|/pa"`를 입력하면 동사와 형용사가 추출됩니다. 그런 다음, `"받"`은 `"받다"`, `"멋지"`는 `"멋지다"`와 같이 단어 뒤에 태그 대신 "~다"를 붙여 이해하기 편하게 수정하겠습니다. `str_replace()`에 텍스트 규칙으로 `"/.*$"`를 입력해  "/로 시작하는 모든 문자"를 "다"로 바꾸면 됩니다. 이렇게 하면 `"받/pv"`는 `"받다"`로, `"멋지/pa"`는 "멋지다"로 바뀝니다. --&gt;


&lt;!-- ```{r} --&gt;
&lt;!-- # 동사, 형용사 추출하기 --&gt;
&lt;!-- pvpa &lt;- comment_pos %&gt;% --&gt;
&lt;!--   filter(str_detect(word, "/pv|/pa")) %&gt;%         # "/pv", "/pa" 추출 --&gt;
&lt;!--   mutate(word = str_replace(word, "/.*$", "다"))  # "/"로 시작 문자를 "다"로 바꾸기 --&gt;

&lt;!-- pvpa %&gt;% --&gt;
&lt;!--   select(word, reply) --&gt;
&lt;!-- ``` --&gt;

&lt;!-- &gt; [편집] 출력 줄맞춤 --&gt;

&lt;!-- &lt;br&gt; --&gt;

&lt;!-- &gt; [참고] `str_detect()`에 여러 문자를 입력할 때는 `|`로 구분해야 합니다. --&gt;



&lt;!-- 이제 댓글에 어떤 동사와 형용사가 가장 많이 사용됐는지 쉽게 알아볼 수 있습니다. --&gt;
&lt;!-- ```{r} --&gt;
&lt;!-- pvpa %&gt;% --&gt;
&lt;!--   count(word, sort = T) --&gt;
&lt;!-- ``` --&gt;


&lt;!-- #### (3) 추출한 데이터 결합하기 --&gt;

&lt;!-- `bind_rows()`를 이용해 추출한 `noun`과 `pvpa`를 하나로 결합하겠습니다. 그런 다음 단어의 의미를 이해할 수 있도록 두 글자 이상의 단어만 남기겠습니다. --&gt;

&lt;!-- ```{r} --&gt;
&lt;!-- # 품사 결합 --&gt;
&lt;!-- comment &lt;- bind_rows(noun, pvpa) %&gt;% --&gt;
&lt;!--   filter(str_count(word) &gt;= 2) %&gt;% --&gt;
&lt;!--   arrange(id) --&gt;

&lt;!-- comment %&gt;% --&gt;
&lt;!--   select(word, reply) --&gt;
&lt;!-- ``` --&gt;

&lt;!-- &gt; [편집] 출력 줄맞춤 --&gt;

&lt;!-- &lt;br&gt; --&gt;

&lt;!-- &gt; [알아두면 좋아요] 명사, 동사, 형용사 추출하는 간략한 코드 --&gt;

&lt;!-- &gt; 명사, 동사, 형용사를 추출해 결합한 다음 두 글장 이상만 남기는 코드를 아래와 같이 줄여서 작성할 수 있습니다. --&gt;

&lt;!-- ```{r eval=F} --&gt;
&lt;!-- comment_new &lt;- comment_pos %&gt;% --&gt;
&lt;!--   separate_rows(word, sep = "[+]") %&gt;% --&gt;
&lt;!--   filter(str_detect(word, "/n|/pv|/pa")) %&gt;% --&gt;
&lt;!--   mutate(word = ifelse(str_detect(word, "/pv|/pa"), --&gt;
&lt;!--                        str_replace(word, "/.*$", "다"), --&gt;
&lt;!--                        str_remove(word, "/.*$"))) %&gt;% --&gt;
&lt;!--   filter(str_count(word) &gt;= 2) %&gt;% --&gt;
&lt;!--   arrange(id) --&gt;
&lt;!-- ``` --&gt;

&lt;!-- &gt; 두 방법으로 만든 데이터는 내용은 같지만 단어의 정렬 순서가 다릅니다. 품사별로 처리해 결합하는 첫 번째 방법은 `id`별로 위쪽에는 명사, 아래쪽에는 동사와 형용사를 나열합니다. 반면 한 번에 처리하는 두 번째 방법은 댓글의 단어 순서에 따라 나열합니다. --&gt;

&lt;!-- &lt;br&gt; --&gt;

&lt;!-- ### 5.1.3 단어 동시 출현 빈도 구하기 - `pairwise_count()` --&gt;

&lt;!-- 토큰화했으니 단어의 동시 출현 빈도를 구할 차례입니다. `widyr` 패키지의 `pairwise_count()`를 이용하면 동시 출현 빈도를 쉽게 구할 수 있습니다. `pairwise_count()`에는 3개의 파라미터를 입력합니다.  --&gt;

&lt;!-- - `item`: 단어가 들어 있는 변수. 여기서는 word를 입력하면 됩니다. --&gt;
&lt;!-- - `feature`: 텍스트를 구분할 고유값이 들어 있는 변수. 여기서는 id를 입력하면 됩니다. --&gt;
&lt;!-- - `sort = T`: 빈도가 높은 순으로 단어를 정렬합니다. --&gt;

&lt;!-- 출력 결과를 보면 어떤 단어가 몇 번씩 함께 사용됐는지 알 수 있습니다. 첫 번째 행을 보면 "영화"와 "기생충"이  111번 함께 사용되었고, 전체 댓글에서 가장 많이 함께 사용된 단어쌍임을 알 수 있습니다. --&gt;

&lt;!-- `pairwise_count()`는 하나의 단어를 기준으로 함께 사용된 나머지 모든 단어의 빈도를 구하므로 출력 결과를 보면 "영화-기생충", "기생충-영화"와 같이 순서를 바꿔가며 같은 빈도를 지니는 행으로 구성된다는 특징이 있습니다. --&gt;

&lt;!-- ```{r eval=F} --&gt;
&lt;!-- install.packages("widyr") --&gt;
&lt;!-- library(widyr) --&gt;

&lt;!-- pair &lt;- comment %&gt;% --&gt;
&lt;!--   pairwise_count(item = word, --&gt;
&lt;!--                  feature = id, --&gt;
&lt;!--                  sort = T) --&gt;
&lt;!-- pair --&gt;
&lt;!-- ``` --&gt;

&lt;!-- ```{r echo=F} --&gt;
&lt;!-- # install.packages("widyr") --&gt;
&lt;!-- library(widyr) --&gt;

&lt;!-- pair &lt;- comment %&gt;% --&gt;
&lt;!--   pairwise_count(item = word, --&gt;
&lt;!--                  feature = id, --&gt;
&lt;!--                  sort = T) --&gt;
&lt;!-- pair --&gt;
&lt;!-- ``` --&gt;


&lt;!-- #### 특정 단어와 자주 함께 사용된 단어 살펴보기 --&gt;

&lt;!-- `filter`를 이용하면 특정 단어와 자주 함께 사용된 단어가 무엇인지 쉽게 알 수 있습니다. --&gt;

&lt;!-- ```{r} --&gt;
&lt;!-- pair %&gt;% filter(item1 == "영화") --&gt;
&lt;!-- pair %&gt;% filter(item1 == "봉준호") --&gt;
&lt;!-- ``` --&gt;

&lt;!-- &gt; [편집] 2단 편집 --&gt;

    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="../libs/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": true,
"ratio": "16:10",
"navigation": {
"scroll": true
}
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
