---
title: "Do it! 쉽게 배우는 R 텍스트 마이닝 - 04 감정 분석: 어떤 마음으로 글을 썼을까?"
author: "김영우"
output:
  xaringan::moon_reader:
    seal: false
    css: ["default", "css/custom.css"]
    lib_dir: libs
    chakra: libs/remark-latest.min.js
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: true
      ratio: '16:10'
      navigation:
        scroll: true
editor_options: 
  chunk_output_type: c=onsole
---

```{r setup, include=FALSE}
options(htmltools.dir.version = FALSE, 
        width = 80,
        # width = 70,
        
        max.print = 80,
        tibble.print_max = 40,
        
        tibble.width = 80,
        # tibble.width = 70,
        
        # pillar.min_chars = Inf, # tibble 문자 출력 제한
        servr.interval = 0.01) # Viewer 수정 반영 속도


knitr::opts_chunk$set(cache = T, warning = F, message = F, 
                      dpi = 300, fig.height = 4, out.width = "100%")

#xaringanExtra::use_tile_view()

library(knitr)
library(icon)
library(here)
```


```{r echo=FALSE}
rm(list = ls())

library(showtext)
font_add_google(name = "Nanum Gothic", family = "nanumgothic")
showtext_auto()
showtext_opts(dpi = 300) # opts_chunk$set(dpi=300)

# code highlighting
hook_source <- knitr::knit_hooks$get('source')
knitr::knit_hooks$set(source = function(x, options) {
  x <- stringr::str_replace(x, "^[[:blank:]]?([^*].+?)[[:blank:]]*#<<[[:blank:]]*$", "*\\1")
  hook_source(x, options)
})


```

class: title0

Do it! 쉽게 배우는 R 텍스트 마이닝

---

<br>

.pull-left[
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
```{r, echo=FALSE, out.width="70%", out.height="70%"}
include_graphics("https://raw.githubusercontent.com/youngwoos/Doit_textmining/main/cover.png")
```
]

.pull-right[

<br>
<br>
<br>

`r fontawesome("github")` [github.com/youngwoos/Doit_textmining](https://github.com/youngwoos/Doit_textmining)

`r fontawesome("facebook-square")` [facebook.com/groups/datacommunity](https://facebook.com/groups/datacommunity)

- [네이버책](https://book.naver.com/bookdb/book_detail.nhn?bid=17891971)
  - [yes24](http://bit.ly/3oUuJOB)
  - [알라딘](http://bit.ly/3oXOSDn)
  - [교보문고](https://bit.ly/2LtNOcB)
]

---

class: title0

04 감정 분석: <br> 어떤 마음으로 글을 썼을까?

---

class: title0-2

We'll make

<br-back-20>

```{r, echo=FALSE, out.width="70%", out.height="70%"}
include_graphics("Image/04/04_2_2.png")
```

---

class: title0-2

and

<br-back-40>

```{r, echo=F, out.width="70%", out.height="70%"}
include_graphics("Image/04/04_4_1.png")
```

---

<br>

.large2[.font-jua[목차]]

.large[.font-jua[04-1 감정 사전 활용하기]]([link](#04-1))

.large[.font-jua[04-2 댓글 감정 분석하기]]([link](#04-2))

.large[.font-jua[04-3 감정 범주별 주요 단어 살펴보기]]([link](#04-3))

.large[.font-jua[04-4 감정 사전 수정하기]]([link](#04-4))


---


name: 04-1
class: title1

04-1 감정 사전 활용하기

---

##### 감정 분석(sentiment analysis)
- 텍스트에 어떤 감정이 담겨있는지 분석하는 방법
  - 글쓴이가 어떤 감정을 담아 글을 썼는가?
  - 사람들이 어떤 주제를 긍정적/부정적으로 느끼는가?

```{r, out.width="80%", eval=F}
include_graphics("Image/etc/04_1_dic.png")
```

---

##### 감정 사전
- '감정 단어'와 '감정의 강도를 표현한 숫자'로 구성된 사전
- 사전을 이용해 문장의 단어에 감정 점수를 부여한 다음 합산

--

#### 감정 사전 살펴보기

- KNU 한국어 감성사전
  - 군산대학교 소프트웨어융합공학과에서 개발
  - `word`: 감정 단어 
  - `polarity`: 감정의 강도

`r fontawesome("lightbulb")` KNU 한국어 감성사전 출처: github.com/park1200656/KnuSentiLex


```{r, eval=FALSE}
# 감정 사전 불러오기
library(dplyr)
library(readr)
dic <- read_csv("knu_sentiment_lexicon.csv")
```

```{r, echo=FALSE}
# 감정 사전 불러오기
library(dplyr)
library(readr)
dic <- read_csv("../Data/knu_sentiment_lexicon.csv")
```

---

.pull-left[
```{r}
# 긍정 단어
dic %>%
  filter(polarity == 2) %>%
  arrange(word)
```
]

.pull-right[

```{r}
# 부정 단어
dic %>%
  filter(polarity == -2) %>%
  arrange(word)
```
]


---

##### 감정 단어의 종류 살펴보기

<br10>

- `word`
  - 한 단어로 된 단일어,  둘 이상 단어 결합된 복합어
  - 이모티콘: `^^`, `ㅠㅠ` 


- `polarity`
  -  5가지 정수(+2, +1, 0, -1, -2)
  - `+`: 긍정 단어, `-`: 부정 단어, `0`: 중성 단어

--

.pull-left[
```{r}
dic %>%
  filter(word %in% c("좋은", "나쁜"))
```
]

.pull-right[
```{r}
dic %>%
  filter(word %in% c("기쁜", "슬픈"))
```
]

---

```{r}
# 이모티콘
library(stringr)
dic %>%
  filter(!str_detect(word, "[가-힣]")) %>%
  arrange(word)

```

---
- 총 14,854개 단어

```{r}
dic %>%
  mutate(sentiment = ifelse(polarity >=  1, "pos",
                     ifelse(polarity <= -1, "neg", "neu"))) %>%
  count(sentiment)
```

---


#### 문장의 감정 점수 구하기

##### 1. 단어 기준으로 토큰화하기
```{r}
df <- tibble(sentence = c("디자인 예쁘고 마감도 좋아서 만족스럽다.",
                          "디자인은 괜찮다. 그런데 마감이 나쁘고 가격도 비싸다."))
df
```

---
- 텍스트를 단어 기준으로 토큰화: 감정 사전과 동일하게
- `unnest_tokens(drop = F)`
  - 원문 제거하지 않기
  - 단어가 어느 문장에서 추출됐는지 알수 있도록

```{r df, eval=F}
library(tidytext)
df <- df %>%
  unnest_tokens(input = sentence,
                output = word,
                token = "words",
                drop = F)

df
```

---

```{r, ref.label = "df" , echo=FALSE}
```


---


#### 단어에 감정 점수 부여하기

- `dplyr::left_join()`: `word` 기준 감정 사전 결합
- 감정 사전에 없는 단어 `polarity` `NA` → `0` 부여

```{r join, eval=F}

df <- df %>%
  left_join(dic, by = "word") %>%
  mutate(polarity = ifelse(is.na(polarity), 0, polarity))

df
```


---

```{r ref.label="join", echo=F}

```

---

##### 3. 문장별로 감정 점수 합산하기

```{r}
score_df <- df %>%
  group_by(sentence) %>%
  summarise(score  = sum(polarity))

score_df
```

---

name: 04-2
class: title1

04-2 댓글 감정 분석하기

---

##### 영화 '기생충' 아카데미상 수상 관련 기사 댓글

#### 기본적인 전처리

- 고유 번호 변수 만들기: 댓글 내용 같아도 구별할 수 있도록
- html 특수 문자 제거하기: 웹에서 만들어진 텍스트는 html 특수 문자 포함되어 내용 알아보기 불편
  - `textclean::replace_html()` : html 태그를 공백으로 바꾸기
  - `stringr::str_squish()`: 중복 공백 제거
- 특수 문자와 두 글자 미만 단어 포함하기: 
  - 감정 사전의 특수 문자, 모음, 자음으로 된 두 글자 미만의 이모티콘 활용


---

```{r eval=F}
# 데이터 불러오기
raw_news_comment <- read_csv("news_comment_parasite.csv")

# 기본적인 전처리
install.packages("textclean")
library(textclean)

news_comment <- raw_news_comment %>%
  mutate(id = row_number(),
         reply = str_squish(replace_html(reply)))

# 데이터 구조 확인
glimpse(news_comment)
```


```{r echo=F, R.options=list(tibble.width = 50)}
# 데이터 불러오기
raw_news_comment <- read_csv("../Data/news_comment_parasite.csv")

# 기본적인 전처리
# install.packages("textclean")
library(textclean)

news_comment <- raw_news_comment %>%
  mutate(id = row_number(),
         reply = str_squish(replace_html(reply)))

# 데이터 구조 확인
glimpse(news_comment)
```


---

#### 단어 기준으로 토큰화하고 감정 점수 부여하기

```{r, token-comment, eval=FALSE}
# 토큰화
word_comment <- news_comment %>%
  unnest_tokens(input = reply,
                output = word,
                token = "words",
                drop = F)

word_comment %>%
  select(word, reply)
```

---

```{r ref.label="token-comment", R.options=list(tibble.width=50), echo=F}
```
---

```{r}
# 감정 점수 부여
word_comment <- word_comment %>%
  left_join(dic, by = "word") %>%
  mutate(polarity = ifelse(is.na(polarity), 0, polarity))

word_comment %>%
  select(word, polarity)
```

---

#### 자주 사용된 감정 단어 살펴보기


##### 1. 감정 분류하기

```{r}
word_comment <- word_comment %>%
  mutate(sentiment = ifelse(polarity ==  2, "pos",
                     ifelse(polarity == -2, "neg", "neu")))

word_comment %>%
  count(sentiment)
```

---

#### 2. 막대 그래프 만들기

```{r top10_sentiment, eval=F}
top10_sentiment <- word_comment %>%
  filter(sentiment != "neu") %>%
  count(sentiment, word) %>%
  group_by(sentiment) %>%
  slice_max(n, n = 10)

top10_sentiment
```

---

```{r ref.label="top10_sentiment", echo=F}
```

---

```{r p-top10_sentiment, fig.show='hide'}
# 막대 그래프 만들기
library(ggplot2)
ggplot(top10_sentiment, aes(x = reorder(word, n),
                            y = n,
                            fill = sentiment)) +
  geom_col() +
  coord_flip() +
  geom_text(aes(label = n), hjust = -0.3) +
  facet_wrap(~ sentiment, scales = "free") +
  scale_y_continuous(expand = expansion(mult = c(0.05, 0.15))) +
  labs(x = NULL) +
  theme(text = element_text(family = "nanumgothic"))
```

`r fontawesome("lightbulb")` `scale_y_continuous()`: 막대-그래프 간격 넓히기. 막대 끝의 빈도 값이 그래프 경계 밖으로 벗어나지 <br> &nbsp;&nbsp;&nbsp;&nbsp;않도록 설정.

---

```{r "p-top10_sentiment", echo=F}
```


---

#### 댓글별 감정 점수 구하고 댓글 살펴보기



##### 1. 댓글별 감정 점수 구하기

- `id`, `reply`별로 분리한 다음 `polarity` 합산
- `id`로 먼저 나누는 이유: 
    - 내용이 같은 댓글이 여럿 있더라도 서로 다른 댓글로 취급
    - `id`별로 먼저 나누지 않으면 내용 같은 댓글 점수 모두 하나로 합산

```{r score_comment, eval=F}
score_comment <- word_comment %>%
  group_by(id, reply) %>%
  summarise(score = sum(polarity)) %>%
  ungroup()

score_comment %>%
  select(score, reply)
```

---

```{r score_comment, echo=F, R.options=list(tibble.width = 50)}
```

---

##### 2. 감정 점수 높은 댓글 살펴보기

```{r R.options=list(tibble.width = 50)}
# 긍정 댓글
score_comment %>%
  select(score, reply) %>%
  arrange(-score)
```

---

##### 2. 감정 점수 높은 댓글 살펴보기

```{r R.options=list(tibble.width = 50)}
# 부정 댓글
score_comment %>%
  select(score, reply) %>%
  arrange(score)
```

---

#### 감정 경향 살펴보기



##### 1. 감정 점수 빈도 구하기


.pull-left[
```{r eval=F}
score_comment %>%
  count(score)
```
]

.pull-right[
```{r echo=F}
score_comment %>%
  count(score)
```
]

---

##### 2. 감정 분류하고 막대 그래프 만들기

```{r}
# 감정 분류하기
score_comment <- score_comment %>%
  mutate(sentiment = ifelse(score >=  1, "pos",
                     ifelse(score <= -1, "neg", "neu")))
```

```{r}
# 감정 빈도와 비율 구하기
frequency_score <- score_comment %>%
  count(sentiment) %>%
  mutate(ratio = n/sum(n)*100)

frequency_score
```

---
```{r, p-frequency_score, fig.show='hide'}
# 막대 그래프 만들기
ggplot(frequency_score, aes(x = sentiment, y = n, fill = sentiment)) +
  geom_col() +
  geom_text(aes(label = n), vjust = -0.3) +
  scale_x_discrete(limits = c("pos", "neu", "neg"))
```

`r fontawesome("lightbulb")` `scale_x_discrete()`: x축 순서 정하기

```{r, ref.label="p-frequency_score", echo=F, out.width="70%"}
# 막대 그래프 만들기
ggplot(frequency_score, aes(x = sentiment, y = n, fill = sentiment)) +
  geom_col() +
  geom_text(aes(label = n), vjust = -0.3) +
  scale_x_discrete(limits = c("pos", "neu", "neg"))
```


---

##### 3. 비율 누적 막대 그래프 만들기

<br10>

- 샘플 데이터로 비율 누적 막대 그래프 만들기
  - 데이터에 x축, y축, 누적 막대를 표현할 변수 필요

```{r, out.width="50%"}
df <- tibble(contry = c("Korea", "Korea", "Japen", "Japen"),  # 축
             sex = c("M", "F", "M", "F"),                     # 누적 막대
             ratio = c(60, 40, 30, 70))                       # 값
df
```


---

```{r, out.width="70%"}
ggplot(df, aes(x = contry, y = ratio, fill = sex)) + geom_col()
```

---

- `geom_text()`: 막대에 비율 표기
- `position_stack(vjust = 0.5)`: 비율을 막대의 가운데에 표시

```{r, out.width="70%"}
ggplot(df, aes(x = contry, y = ratio, fill = sex)) +
  geom_col() +
  geom_text(aes(label = paste0(ratio, "%")),          # % 표시
            position = position_stack(vjust = 0.5))   # 가운데 표시
```

---

**댓글의 감정 비율로 누적 막대 그래프 만들기**
- x축을 구성할 더미 변수(dummy variable) 추가

```{r}
# 더미 변수 생성
frequency_score$dummy <- 0
frequency_score
```

---

```{r fig.width=4, fig.height=4}
ggplot(frequency_score, aes(x = dummy, y = ratio, fill = sentiment)) +
  geom_col() +
  geom_text(aes(label = paste0(round(ratio, 1), "%")),
              position = position_stack(vjust = 0.5)) +
  theme(axis.title.x = element_blank(),  # x축 이름 삭제
        axis.text.x  = element_blank(),  # x축 값 삭제
        axis.ticks.x = element_blank())  # x축 눈금 삭제
```

---

<!-- ## 4.3 감정 분류별 주요 단어 살펴보기 -->

<!-- 텍스트가 구체적으로 어떤 내용을 담고 있는지 파악하려면 감정 점수가 부여되지 않은 단어까지 포함해 분석해야 합니다. 긍정 댓글과 부정 댓글에 어떤 단어가 많이 사용되었는지 분석해 보겠습니다. -->

<!-- ### 4.3.1 자주 사용된 단어 살펴보기 -->

<!-- 먼저, 문장별 감정 점수가 부여된 `score_comment`를 단어 기준으로 토큰화하고, 의미를 해석할 수 있게 두 글자 이상인 한글 단어만 남기겠습니다. -->

<!-- #### 1. 토큰화하고 두 글자 이상 한글 단어만 남기기 -->

<!-- 앞에서 감정 점수를 구할 때는 감정 사전의 특수문자, 모음, 자음으로 된 이모티콘도 활용해야 하므로 특수문자를 제거하고 두 글자 이상의 한글 단어만 남기는 작업을 하지 않았습니다. 여기서는 감정 단어가 아니라 의미를 해석할 수 있는 단어를 분석하므로 두 글자 이상인 한글 단어만 남기는 작업을 해야 합니다. -->

<!-- ```{r} -->
<!-- comment <- score_comment %>% -->
<!--   unnest_tokens(input = reply,          # 단어 기준 토큰화 -->
<!--                 output = word, -->
<!--                 token = "words", -->
<!--                 drop = F) %>% -->
<!--   filter(str_detect(word, "[가-힣]") &  # 한글 추출 -->
<!--          str_count(word) >= 2)          # 두 글자 이상 추출 -->
<!-- ``` -->

<!-- > [참고] 이 코드는 `word`에 `"문장a"` 처럼 한글이 아닌 문자가 함께 있어도 추출합니다. 한글이 아닌 문자가 포함된 행을 제외하려면 `filter(!str_detect(word, "[^가-힣]"))`를 입력하면 됩니다. 여기서는 그런 문자가 없어서 어떤 방식이든 결과가 같습니다. -->

<!-- #### 2. 감정 분류별 빈도 구하기 -->

<!-- `comment`의 `sentiment`별 `word`의 빈도를 구해서 긍정 댓글과 부정 댓글에 어떤 단어가 많이 사용됐는지 살펴보겠습니다. -->

<!-- ```{r} -->
<!-- # 감정 및 단어별 빈도 구하기 -->
<!-- frequency_word <- comment %>% -->
<!--   filter(str_count(word) >= 2) %>% -->
<!--   count(sentiment, word, sort = T) -->
<!-- ``` -->


<!-- ```{r} -->
<!-- # 긍정 댓글 고빈도 단어 -->
<!-- frequency_word %>% -->
<!--   filter(sentiment == "pos") -->

<!-- # 부정 댓글 고빈도 단어 -->
<!-- frequency_word %>% -->
<!--   filter(sentiment == "neg") -->
<!-- ``` -->

<!-- 추출한 단어를 보면 긍정 댓글과 부정 댓글이 다루고 있는 내용에 어떤 차이가 있는지 이해할 수 있습니다. 하지만 `"봉준호"`, `"기생충"`, `"영화"`와 같은 동일한 단어도 많이 추출되었습니다. 이는 단순히 양쪽에서 빈도가 높은 단어를 추출했기 때문입니다. 긍정 댓글과 부정 댓글의 차이를 이해하려면 상대적으로 많이 사용된 단어를 추출해 비교해야 합니다. -->

