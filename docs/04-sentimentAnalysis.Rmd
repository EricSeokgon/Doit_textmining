---
title: "Do it! 쉽게 배우는 R 텍스트 마이닝 - 03 비교 분석: 무엇이 다를까?"
author: "김영우"
output:
  xaringan::moon_reader:
    seal: false
    css: ["default", "css/custom.css"]
    lib_dir: libs
    chakra: libs/remark-latest.min.js
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
      ratio: '16:10'
      navigation:
        scroll: true
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
options(htmltools.dir.version = FALSE, 
        width = 80,
        # width = 70,
        
        max.print = 80,
        tibble.print_max = 40,
        
        tibble.width = 80,
        # tibble.width = 70,
        
        # pillar.min_chars = Inf, # tibble 문자 출력 제한
        servr.interval = 0.01) # Viewer 수정 반영 속도


knitr::opts_chunk$set(cache = T, warning = F, message = F, 
                      dpi = 300, fig.height = 4, out.width = "100%")

xaringanExtra::use_tile_view()

library(knitr)
library(icon)
library(here)
```


```{r echo=FALSE}
rm(list = ls())

library(showtext)
font_add_google(name = "Nanum Gothic", family = "nanumgothic")
showtext_auto()
showtext_opts(dpi = 300) # opts_chunk$set(dpi=300)

# code highlighting
hook_source <- knitr::knit_hooks$get('source')
knitr::knit_hooks$set(source = function(x, options) {
  x <- stringr::str_replace(x, "^[[:blank:]]?([^*].+?)[[:blank:]]*#<<[[:blank:]]*$", "*\\1")
  hook_source(x, options)
})


```

class: title0

Do it! 쉽게 배우는 R 텍스트 마이닝

---

<br>

.pull-left[
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
```{r, echo=FALSE, out.width="70%", out.height="70%"}
include_graphics("https://raw.githubusercontent.com/youngwoos/Doit_textmining/main/cover.png")
```
]

.pull-right[

<br>
<br>
<br>

`r fontawesome("github")` [github.com/youngwoos/Doit_textmining](https://github.com/youngwoos/Doit_textmining)

`r fontawesome("facebook-square")` [facebook.com/groups/datacommunity](https://facebook.com/groups/datacommunity)

- [네이버책](https://book.naver.com/bookdb/book_detail.nhn?bid=17891971)
  - [yes24](http://bit.ly/3oUuJOB)
  - [알라딘](http://bit.ly/3oXOSDn)
  - [교보문고](https://bit.ly/2LtNOcB)
]

---

class: title0

03 비교 분석: 무엇이 다를까?

---

class: title0-2

We'll make

<br-back-20>

```{r, echo=FALSE, out.width="70%", out.height="70%"}
include_graphics("Image/03/03_3_1.png")
```

---

class: title0-2

and

<br-back-40>

```{r, echo=F, out.width="70%", out.height="70%"}
include_graphics("Image/03/03_4_1.png")
```

---

<br>

.large2[.font-jua[목차]]

.large[.font-jua[03-1 단어 빈도 비교하기]]([link](#03-1))

.large[.font-jua[03-2 오즈비 - 상대적으로 중요한 단어 비교하기]]([link](#03-2))

.large[.font-jua[03-3 로그 오즈비로 단어 비교하기]]([link](#03-3))

.large[.font-jua[03-4 TF-IDF - 여러 텍스트의 단어 비교하기]]([link](#03-4))

---


name: 03-1
class: title1

03-1 단어 빈도 비교하기

---

# 4. 감정 분석 - 어떤 마음으로 글을 썼을까?

텍스트에 어떤 감정이 담겨있는지 분석하는 방법을 **감정 분석(Sentiment Analysis)**이라고 합니다. 감정 분석을 하면 글쓴이가 어떤 감정을 담아 글을 썼는지, 사람들이 어떤 주제를 긍정적으로 느끼는지 아니면 부정적으로 느끼는지 파악할 수 있습니다. 텍스트의 감정을 분석하는 방법을 알아보겠습니다.


<!-- ## 4.1 감정 사전 활용하기 -->

<!-- 감정 분석에는 '감정 사전'을 활용합니다. 감정 사전은 감정을 나타낸 단어와 감정의 강도를 표현한 숫자로 구성되어 있습니다. 감정 사전을 이용해 단어에 감정 점수를 부여한 다음 합산하면 문장에 어떤 감정이 담겨 있는지 파악할 수 있습니다. 군산대학교 소프트웨어융합공학과에서 만든 'KNU 한국어 감성사전'을 이용해 감정 분석을 하는 방법을 알아보겠습니다.  -->

<!-- > [참고] -->
<!-- > 'KNU 한국어 감성사전' 깃허브 주소: github.com/park1200656/KnuSentiLex -->

<!-- ```{r echo=FALSE, out.width = '100%'} -->
<!-- knitr::include_graphics(here::here("img/04_sentiment_dic.png")) -->
<!-- ``` -->

<!-- > [편집] 이미지 작업, 박스 처리로 눈에 띄게 표현하기 -->


<!-- ### 4.1.1 감정 사전 살펴보기 -->

<!-- 우선 감정 사전을 불러와 구조를 살펴보겠습니다. 감정 사전은 감정 단어를 나타낸 `word`와 감정의 강도를 숫자로 표현한  `polarity`로 구성됩니다. -->

<!-- ```{r, eval=FALSE} -->
<!-- # 감정 사전 불러오기 -->
<!-- library(readr) -->
<!-- dic <- read_csv("knu_sentiment_lexicon.csv") -->
<!-- ``` -->

<!-- ```{r, echo=FALSE} -->
<!-- # 감정 사전 불러오기 -->
<!-- library(readr) -->
<!-- dic <- read_csv(here::here("files/knu_sentiment_lexicon.csv")) -->
<!-- ``` -->

<!-- ```{r} -->
<!-- library(dplyr) -->

<!-- # 긍정 단어 -->
<!-- dic %>%  -->
<!--   filter(polarity == 2) %>%  -->
<!--   arrange(word) -->

<!-- # 부정 단어 -->
<!-- dic %>%  -->
<!--   filter(polarity == -2) %>%  -->
<!--   arrange(word) -->
<!-- ``` -->

<!-- > [편집] 2단 편집 -->

<!-- #### 감정 사전에 있는 단어의 종류 -->

<!-- `word`는 한 단어로 구성된 단일어, 두 개 이상의 단어가 결합된 복합어, `^^`, `ㅠㅠ`와 같은 이모티콘으로 구성됩니다. `polarity`는 `+2`에서 `-2`까지 5단계의 정수로 되어 있는데, 긍정 단어는 `+`, 부정 단어는 `-`로 표현됩니다. 긍정과 부정 중 어느 한쪽으로 판단하기 어려운 중성 단어는 `0`으로 표현됩니다.  -->

<!-- ```{r} -->
<!-- dic %>%  -->
<!--   filter(word %in% c("좋은", "나쁜")) -->
<!-- ``` -->

<!-- ```{r} -->
<!-- dic %>%  -->
<!--   filter(word %in% c("기쁜", "슬픈")) -->
<!-- ``` -->

<!-- ```{r} -->
<!-- dic %>% -->
<!--   filter(word %in% c("행복하다", "좌절하다")) -->
<!-- ``` -->

<!-- ```{r} -->
<!-- # 이모티콘 -->
<!-- library(stringr) -->
<!-- dic %>%  -->
<!--   filter(!str_detect(word, "[가-힣]")) %>%  -->
<!--   arrange(word) -->
<!-- ``` -->

<!-- 감정 사전은 총 14,854개 단어로 구성되어 있습니다. 긍정 단어 4,871개, 부정 단어 9,829개, 중성 단어 154개로 구성됩니다. -->
<!-- ```{r} -->
<!-- dic %>%  -->
<!--   mutate(sentiment = ifelse(polarity >=  1, "pos", -->
<!--                      ifelse(polarity <= -1, "neg", "neu"))) %>%  -->
<!--   count(sentiment) -->
<!-- ``` -->


<!-- ### 4.1.2 문장의 감정 점수 구하기 -->

<!-- #### 1. 단어 기준으로 토큰화하기 -->

<!-- 감정 사전을 활용해 문장의 감정 점수를 구하는 방법을 알아보겠습니다. 우선, 분석할 텍스트의 단어가 감정 사전에 있는지 찾을 수 있게 토큰화해야 합니다. 감정 사전은 형태소가 아니라 단어 기준으로 구성되어 있으므로 분석할 텍스트도 단어 기준으로 토큰화해야 합니다. -->

<!-- `unnest_tokens()`를 이용해 샘플 텍스트를 단어 기준으로 토큰화하겠습니다. 이때 `drop = F`를 입력해 원문을 보유하겠습니다. 이렇게 하면 각 단어가 어느 문장에서 추출됐는지 알 수 있습니다. -->

<!-- ```{r} -->
<!-- df <- tibble(sentence = c("디자인 예쁘고 마감도 좋아서 만족스럽다.", -->
<!--                           "디자인은 괜찮다. 그런데 마감이 나쁘고 가격도 비싸다.")) -->
<!-- df -->

<!-- library(tidytext) -->
<!-- df <- df %>%  -->
<!--   unnest_tokens(input = sentence, -->
<!--                 output = word, -->
<!--                 token = "words", -->
<!--                 drop = F) -->

<!-- df %>% print(n = Inf) -->
<!-- ``` -->

<!-- #### 2. 토큰화한 단어에 감정 점수 부여하기 -->

<!-- 토큰화한 단어에 감정 점수를 부여하겠습니다. `dplyr` 패키지의 `left_join()`을 이용해  `word` 기준으로 감정 사전을 결합하면 각 단어에 감정 점수를 부여할 수 있습니다. 단어가 감정 사전에 없으면 `polarity`의 값이 `NA`가 되는데, 이때는 `0`을 부여하겠습니다. -->

<!-- 출력 결과를 보면 첫 번째 문장의 `"예쁘고"`, `"좋아서"`, `"만족스럽다"`에 긍정 점수가 부여됐습니다. 두 번째 문장은 `"괜찮다"`에 긍정 점수가 부여됐고, `"나쁘고"`, `"비싸다"`에는 부정 점수가 부여됐습니다. -->

<!-- ```{r} -->
<!-- df <- df %>%  -->
<!--   left_join(dic, by = "word") %>%  -->
<!--   mutate(polarity = ifelse(is.na(polarity), 0, polarity)) -->

<!-- df %>% print(n = Inf) -->
<!-- ``` -->

<!-- #### 3. 문장별로 감정 점수 합산하기 -->

<!-- 이제 `sencence`별로 감정 점수를 합산하겠습니다. 출력 결과를 보면 첫 번째 문장은 세 단어가 `+2`이므로 합산해 `6`이 되었습니다. 두 번째 문장은 한 단어는 `+1`, 두 단어는 `-2`이므로 합산해 `-3`이 되었습니다. -->

<!-- ```{r} -->
<!-- score_df <- df %>%  -->
<!--   group_by(sentence) %>%  -->
<!--   summarise(score  = sum(polarity)) -->

<!-- score_df -->
<!-- ``` -->

<!-- ## 4.2 기사 댓글 감정 분석하기 -->

<!-- 이제 실제 텍스트를 이용해 감정 분석을 해보겠습니다. `"news_comment_parasite.csv"`에는 2020년 2월 10일 영화 '기생충'의 아카데미상 수상 소식을 다룬 기사에 달린 댓글이 들어 있습니다. 댓글을 분석해 긍정적인 댓글과 부정적인 댓글 중 무엇이 더 많은지, 어떤 내용의 댓글이 달렸는지 알아보겠습니다. -->


<!-- ### 4.2.1 기본적인 전처리 -->

<!-- 우선 기사 댓글 데이터를 불러와 기본적인 전처리를 하겠습니다.  -->

<!-- **고유 번호 변수 만들기** : 댓글의 내용이 같아도 구별할 수 있도록 `mutate()`와 `row_number()`를 이용해 고유 번호 `id`를 추가하겠습니다.  -->

<!-- **html 특수 문자 제거하기** : 웹에서 만들어진 텍스트는 `&nbsp;`과 같은 html 특수 문자가 포함되어 있어서 출력하면 내용을 알아보기 불편합니다. `textclean` 패키지의 `replace_html()`을 이용해 html 태그를 공백으로 바꾼 다음 `stringr` 패키지의 `str_squish()`를 이용해 중복 공백을 제거하겠습니다. -->

<!-- **두 글자 미만 단어 포함하기** : 다음 코드를 보면 앞 장과 달리 특수문자를 제거하고 두 글자 이상의 단어만 남기는 작업을 하지 않았습니다. 감정 사전에 특수문자, 모음, 자음으로 된 이모티콘도 포함되어 있는데, 이런 단어들도 텍스트의 감정을 분석하는데 활용해야 하기 때문입니다. -->


<!-- ```{r eval=F} -->
<!-- # 데이터 불러오기 -->
<!-- raw_news_comment <- read_csv("news_comment_parasite.csv") -->
<!-- ``` -->

<!-- ```{r echo=F} -->
<!-- # 데이터 불러오기 -->
<!-- raw_news_comment <- read_csv(here::here("files/news_comment_parasite.csv")) -->

<!-- ``` -->


<!-- ```{r eval=F} -->
<!-- # 기본적인 전처리 -->
<!-- install.packages("textclean") -->
<!-- library(textclean) -->

<!-- news_comment <- raw_news_comment %>% -->
<!--   mutate(id = row_number(), -->
<!--          reply = str_squish(replace_html(reply))) -->

<!-- # 데이터 구조 확인 -->
<!-- glimpse(news_comment) -->
<!-- ``` -->

<!-- ```{r echo=F} -->
<!-- # 기본적인 전처리 -->
<!-- # install.packages("textclean") -->
<!-- library(textclean) -->

<!-- news_comment <- raw_news_comment %>% -->
<!--   mutate(id = row_number(), -->
<!--          reply = str_squish(replace_html(reply))) -->

<!-- glimpse(news_comment, width = 60) -->
<!-- ``` -->

<!-- > [참고] `glimpse()`는 데이터 구조를 요약해 보여주는 `dplyr` 패키지의 함수입니다. 요약 결과를 줄을 맞춰 출력하기 때문에 `str()`보다 데이터 구조를 파악하기 좋습니다. -->


<!-- ### 4.2.2 단어 기준으로 토큰화하고 감정 점수 부여하기 -->

<!-- `news_comment`를 단어 기준으로 토큰화하고 각 단어에 감정 점수를 부여하겠습니다. -->

<!-- ```{r} -->
<!-- # 토큰화 -->
<!-- word_comment <- news_comment %>% -->
<!--   unnest_tokens(input = reply, -->
<!--                 output = word, -->
<!--                 token = "words", -->
<!--                 drop = F) -->

<!-- word_comment %>% -->
<!--   select(word, reply) -->

<!-- # 감정 점수 부여 -->
<!-- word_comment <- word_comment %>% -->
<!--   left_join(dic, by = "word") %>% -->
<!--   mutate(polarity = ifelse(is.na(polarity), 0, polarity)) -->

<!-- word_comment %>% -->
<!--   select(word, polarity) -->
<!-- ``` -->

<!-- ### 4.2.3 자주 사용된 감정 단어 살펴보기 -->

<!-- 댓글별로 감정 점수를 합산하기 전에, 우선 어떤 감정 단어가 많이 사용되었는지 알아보겠습니다. -->

<!-- #### 1. 감정 분류하기 -->

<!-- 감정이 분명하게 드러난 단어를 중심으로 살펴보기 위해 `polarity`가 `2`면 긍정(pos), `-2`면 부정(neg), 그 외에는 중립(neu)을 부여한 변수 `sentiment`를 만들겠습니다. `sentiment`로 빈도를 구하면 어떤 감정의 단어가 많은지 알 수 있습니다. -->

<!-- ```{r} -->
<!-- word_comment <- word_comment %>% -->
<!--   mutate(sentiment = ifelse(polarity ==  2, "pos", -->
<!--                      ifelse(polarity == -2, "neg", "neu"))) -->

<!-- word_comment %>% -->
<!--   count(sentiment) -->
<!-- ``` -->

<!-- #### 2. 막대 그래프 만들기 -->

<!-- 중립 단어는 제외하고, 긍정 단어와 부정 단어 중 가장 많이 사용 된 단어를 10개씩 추출해 막대 그래프를 만들겠습니다. -->

<!-- ```{r} -->
<!-- top10_sentiment <- word_comment %>% -->
<!--   filter(sentiment != "neu") %>% -->
<!--   count(sentiment, word) %>% -->
<!--   group_by(sentiment) %>% -->
<!--   slice_max(n, n = 10) -->

<!-- top10_sentiment -->
<!-- ``` -->

<!-- ```{r} -->
<!-- # 막대 그래프 만들기 -->
<!-- library(ggplot2) -->
<!-- ggplot(top10_sentiment, aes(x = reorder(word, n),  -->
<!--                             y = n,  -->
<!--                             fill = sentiment)) + -->
<!--   geom_col() + -->
<!--   coord_flip() + -->
<!--   geom_text(aes(label = n), hjust = -0.3) + -->
<!--   facet_wrap(~ sentiment, scales = "free") + -->
<!--   scale_y_continuous(expand = expansion(mult = c(0.05, 0.15))) +   -->
<!--   labs(x = NULL) + -->
<!--   theme(text = element_text(family = "nanumgothic")) -->
<!-- ``` -->

<!-- > [참고] `scale_y_continuous()`에 적용한 `expansion()`은 막대와 그래프 경계의 간격을 넓히는 기능을 합니다. 막대 밖에 표현한 빈도 값이 그래프 경계 밖으로 벗어나지 않도록 하려고 사용했습니다. -->

<!-- 그래프를 보면 긍정 단어는 `"대단하다"`, `"자랑스럽다"`, `"축하"` 등의 빈도가 높습니다. 아카데미상을 수상한 제작진을 칭찬하는 댓글에 사용된 단어라고 예상할 수 있습니다. 부정 단어는 `"소름"`, `"아니다"`, `"우울한"` 등의 빈도가 높습니다. 영화 내용과 관련된 부정적인 감정을 표현한 댓글들에 사용된 단어라고 예상할 수 있습니다. -->

<!-- 앞에서 살펴본 단어들은 댓글에 사용된 단어 중 감정 사전과 매칭된 일부 입니다. 본격적으로 분석을 하기 전에 어떤 감정 단어가 많이 사용되었는지 알아보려고 감정이 분명하게 들어난 단어만 추출해본 것입니다. 텍스트의 전반적인 내용을 파악하려면 감정 점수가 부여되지 않은 중립 단어까지 포함해서 분석해야 합니다. 이 방법은 뒤에서 다루겠습니다. -->

<!-- > [참고] `"소름"`, `"미친"` 등은 부정적인 단어가 아니라 긍정적인 감정을 극적으로 표현하는 단어일 수 있기 때문에 감정 사전을 수정해서 점수를 부여해야 합니다. 이에 대해서는 **4.4**에서 자세히 다룹니다. -->

<!-- ### 4.2.4 댓글별 감정 점수 구하고 댓글 살펴보기 -->

<!-- 댓글별로 감정 점수를 구한 다음 감정 점수가 높은 댓글이 어떤 내용을 담고 있는지 살펴보겠습니다. -->


<!-- #### 1. 댓글별 감정 점수 구하기 -->

<!-- `word_comment`를 `id`, `reply`별로 분리한 다음 `polarity`를 합산해 감정 점수를 구하겠습니다. 그런 다음 이후 분석 작업은 그룹별로 처리하지 않도록 `ungroup()`으로 그룹을 해제하겠습니다. -->

<!-- `id`로 먼저 나누는 이유는 내용이 같은 댓글이 여럿 있더라도 서로 다른 댓글로 취급하기 위함입니다. `id`별로 먼저 나누지 않으면 내용이 같은 댓글들의 점수가 모두 하나로 합산됩니다. -->

<!-- ```{r} -->
<!-- score_comment <- word_comment %>% -->
<!--   group_by(id, reply) %>% -->
<!--   summarise(score = sum(polarity)) %>% -->
<!--   ungroup() -->

<!-- score_comment %>%  -->
<!--   select(score, reply) -->
<!-- ``` -->


<!-- #### 2. 감정 점수 높은 댓글 살펴보기 -->

<!-- 감정 점수 기준으로 정렬하면 감정이 분명하게 드러난 댓글의 내용을 살펴볼 수 있습니다. 출력 결과에서 감정 점수가 높은 댓글을 보면 제작진의 수상을 축하하고 대한민국의 위상이 올라간 것을 기뻐하는 긍정적인 내용이 주를 이루고 있습니다. 감정 점수가 낮은 댓글을 보면 감독의 정치적 성향이나 영화 내용으로 연상되는 사회 문제를 비판하는 부정적인 내용이 주를 이루고 있습니다. -->

<!-- ```{r} -->
<!-- # 긍정 댓글 -->
<!-- score_comment %>% -->
<!--   select(score, reply) %>%  -->
<!--   arrange(-score) -->

<!-- # 부정 댓글 -->
<!-- score_comment %>% -->
<!--   select(score, reply) %>%  -->
<!--   arrange(score) -->
<!-- ``` -->


<!-- ### 4.2.5 감정 경향 살펴보기 -->

<!-- 댓글에 긍정적인 내용이 많은지 아니면 부정적인 내용이 많은지, 전반적인 감정 경향을 알아보겠습니다. -->

<!-- #### 1. 감정 점수 빈도 구하기 -->

<!-- 댓글의 감정 점수 빈도를 보면 감정 사전에 없는 단어만 사용해 0점이 부여된 댓글이 가장 많고, 감정 점수가 높거나 낮을수록 빈도가 낮음을 알 수 있습니다. -->

<!-- ```{r} -->
<!-- score_comment %>% -->
<!--   count(score) %>% -->
<!--   print(n = Inf) -->
<!-- ``` -->

<!-- #### 2. 감정 분류하고 막대 그래프 만들기 -->

<!-- `score` 기준으로 댓글의 감정을 분류하겠습니다. `1` 이상이면 `pos`(긍정), `-1` 이하면 `neg`(부정), 그 외에는 `neu`(중립)으로 분류하겠습니다. -->

<!-- ```{r} -->
<!-- score_comment <- score_comment %>% -->
<!--   mutate(sentiment = ifelse(score >=  1, "pos", -->
<!--                      ifelse(score <= -1, "neg", "neu"))) -->
<!-- ``` -->

<!-- `sentiment`별 빈도와 비율을 구한 다음 막대 그래프를 만들어 댓글의 전반적인 감정 경향을 살펴보겠습니다. 출력 결과를 보면 중립 댓글이 70%로 가장 많고, 긍정 댓글은 19.5%, 부정 댓글은 10.5%임을 알 수 있습니다. -->

<!-- ```{r} -->
<!-- frequency_score <- score_comment %>% -->
<!--   count(sentiment) %>% -->
<!--   mutate(ratio = n/sum(n)*100) -->

<!-- frequency_score -->

<!-- # 막대 그래프 만들기 -->
<!-- ggplot(frequency_score, aes(x = sentiment, y = n, fill = sentiment)) + -->
<!--   geom_col() + -->
<!--   geom_text(aes(label = n), vjust = -0.3) +  -->
<!--   scale_x_discrete(limits = c("pos", "neu", "neg")) -->
<!-- ``` -->
<!-- > [참고] `scale_x_discrete()`는 x축 순서를 정하는 기능을 합니다. 따로 정하지 않으면 항목의 알파벳 순서로 정렬합니다. -->


<!-- #### 3. 비율 누적 막대 그래프 만들기 -->

<!-- 이번에는 누적 막대 그래프를 만들어 보겠습니다. 누적 막대 그래프를 만들면 하나의 막대 위에 여러 집단의 비율을 표현하기 때문에 구성 요소의 비중 차이를 한눈에 파악할 수 있습니다. -->

<!-- #### 샘플 데이터로 비율 누적 막대 그래프 만들어보기 -->

<!-- 먼저 샘플 데이터로 누적 막대 그래프를 만들어 보겠습니다. 누적 막대 그래프를 만들려면 데이터에 x축, y축, 누적 막대를 표현할 세 가지 변수가 있어야 합니다. 다음 코드로 출력한 그래프를 보면, x축이 `contry`, y축이 `ratio`로 구성되고, 각 막대가 `fill`에 지정된 `sex`별로 누적되어 있습니다. -->

<!-- ```{r} -->
<!-- df <- tibble(contry = c("Korea", "Korea", "Japen", "Japen"),  # 축 -->
<!--              sex = c("M", "F", "M", "F"),                     # 누적 막대 -->
<!--              ratio = c(60, 40, 30, 70))                       # 값 -->
<!-- df -->

<!-- ggplot(df, aes(x = contry, y = ratio, fill = sex)) + geom_col() -->

<!-- ``` -->

<!-- `geom_text()`를 이용하면 막대에 비율을 표기할 수 있습니다. 다음 코드에서 `paste0()`는 비율에 `%`를 붙여 표시하는 기능을 하고, `position_stack(vjust = 0.5)`은 비율을 막대의 가운데에 표시하는 기능을 합니다. -->

<!-- ```{r} -->
<!-- ggplot(df, aes(x = contry, y = ratio, fill = sex)) +  -->
<!--   geom_col() + -->
<!--   geom_text(aes(label = paste0(ratio, "%")),          # % 표시 -->
<!--             position = position_stack(vjust = 0.5))   # 가운데 표시 -->
<!-- ``` -->


<!-- #### 댓글의 감정 비율로 누적 막대 그래프 만들기 -->

<!-- 이제 댓글의 감정 비율을 나타낸 `frequency_score`를 이용해 누적 막대 그래프를 만들겠습니다. y축에 `ratio`, 누적 막대에 `sentiment`를 지정하면 됩니다. 그런데 `frequency_score`에는 샘플 데이터의 `contry`처럼 x축을 구성할 변수가 없습니다. 이럴 때는 더미 변수(Dummy variable)를 만들어 활용하면 됩니다. `frequency_score`에 `dummy` 변수를 추가해 아무 값이나 입력하겠습니다. 여기서는 `0`을 입력했지만 다른 어떤 값을 입력해도 괜찮습니다. -->

<!-- > [참고] 더미 변수는 분석에 활용하기 위해 만든 가짜 변수를 의미합니다. -->

<!-- ```{r} -->
<!-- # 더미 변수 생성 -->
<!-- frequency_score$dummy <- 0 -->
<!-- frequency_score -->
<!-- ``` -->

<!-- 이제 막대 그래프를 만들겠습니다. x축에는 `dummy`, y축에는 `ratio`, `fill`에는 `sentiment`를 입력한 다음 `geom_col()`을 이용해 그래프를 만들겠습니다. `ratio`는 `round()`를 이용해 소수점 둘째 자리에서 반올림하겠습니다. 그런 다음 `theme()`을 이용해 x축의 이름, 값, 눈금을 삭제하겠습니다. 출력한 그래프를 보면 막대가 `sentiment` 비율에 따라 구분되므로 어떤 감정으로 분류된 댓글이 많은지 쉽게 이해할 수 있습니다. -->

<!-- ```{r fig.width=4, fig.height=4} -->
<!-- ggplot(frequency_score, aes(x = dummy, y = ratio, fill = sentiment)) + -->
<!--   geom_col() + -->
<!--   geom_text(aes(label = paste0(round(ratio, 1), "%")),       -->
<!--               position = position_stack(vjust = 0.5)) +  -->
<!--   theme(axis.title.x = element_blank(),  # x축 이름 삭제 -->
<!--         axis.text.x  = element_blank(),  # x축 값 삭제 -->
<!--         axis.ticks.x = element_blank())  # x축 눈금 삭제 -->
<!-- ``` -->


<!-- ## 4.3 감정 분류별 주요 단어 살펴보기 -->

<!-- 텍스트가 구체적으로 어떤 내용을 담고 있는지 파악하려면 감정 점수가 부여되지 않은 단어까지 포함해 분석해야 합니다. 긍정 댓글과 부정 댓글에 어떤 단어가 많이 사용되었는지 분석해 보겠습니다. -->

<!-- ### 4.3.1 자주 사용된 단어 살펴보기 -->

<!-- 먼저, 문장별 감정 점수가 부여된 `score_comment`를 단어 기준으로 토큰화하고, 의미를 해석할 수 있게 두 글자 이상인 한글 단어만 남기겠습니다. -->

<!-- #### 1. 토큰화하고 두 글자 이상 한글 단어만 남기기 -->

<!-- 앞에서 감정 점수를 구할 때는 감정 사전의 특수문자, 모음, 자음으로 된 이모티콘도 활용해야 하므로 특수문자를 제거하고 두 글자 이상의 한글 단어만 남기는 작업을 하지 않았습니다. 여기서는 감정 단어가 아니라 의미를 해석할 수 있는 단어를 분석하므로 두 글자 이상인 한글 단어만 남기는 작업을 해야 합니다. -->

<!-- ```{r} -->
<!-- comment <- score_comment %>% -->
<!--   unnest_tokens(input = reply,          # 단어 기준 토큰화 -->
<!--                 output = word, -->
<!--                 token = "words", -->
<!--                 drop = F) %>% -->
<!--   filter(str_detect(word, "[가-힣]") &  # 한글 추출 -->
<!--          str_count(word) >= 2)          # 두 글자 이상 추출 -->
<!-- ``` -->

<!-- > [참고] 이 코드는 `word`에 `"문장a"` 처럼 한글이 아닌 문자가 함께 있어도 추출합니다. 한글이 아닌 문자가 포함된 행을 제외하려면 `filter(!str_detect(word, "[^가-힣]"))`를 입력하면 됩니다. 여기서는 그런 문자가 없어서 어떤 방식이든 결과가 같습니다. -->

<!-- #### 2. 감정 분류별 빈도 구하기 -->

<!-- `comment`의 `sentiment`별 `word`의 빈도를 구해서 긍정 댓글과 부정 댓글에 어떤 단어가 많이 사용됐는지 살펴보겠습니다. -->

<!-- ```{r} -->
<!-- # 감정 및 단어별 빈도 구하기 -->
<!-- frequency_word <- comment %>% -->
<!--   filter(str_count(word) >= 2) %>% -->
<!--   count(sentiment, word, sort = T) -->
<!-- ``` -->


<!-- ```{r} -->
<!-- # 긍정 댓글 고빈도 단어 -->
<!-- frequency_word %>% -->
<!--   filter(sentiment == "pos") -->

<!-- # 부정 댓글 고빈도 단어 -->
<!-- frequency_word %>% -->
<!--   filter(sentiment == "neg") -->
<!-- ``` -->

<!-- 추출한 단어를 보면 긍정 댓글과 부정 댓글이 다루고 있는 내용에 어떤 차이가 있는지 이해할 수 있습니다. 하지만 `"봉준호"`, `"기생충"`, `"영화"`와 같은 동일한 단어도 많이 추출되었습니다. 이는 단순히 양쪽에서 빈도가 높은 단어를 추출했기 때문입니다. 긍정 댓글과 부정 댓글의 차이를 이해하려면 상대적으로 많이 사용된 단어를 추출해 비교해야 합니다. -->


<!-- ### 4.3.2 상대적으로 자주 사용된 단어 비교하기 -->

<!-- 로그 오즈비를 구해 긍정 댓글과 부정 댓글에서 상대적으로 많이 사용된 단어가 무엇인지 살펴보겠습니다. -->


<!-- #### 1. 로그 오즈비 구하기 -->

<!-- 먼저 `frequency_word` 를 Wide form으로 변환한 뒤 로그 오즈비를 계산하겠습니다. -->

<!-- ```{r} -->
<!-- library(tidyr) -->
<!-- comment_wide <- frequency_word %>% -->
<!--   filter(sentiment != "neu") %>%  # 중립 제외 -->
<!--   pivot_wider(names_from = sentiment, -->
<!--               values_from = n, -->
<!--               values_fill = list(n = 0)) -->

<!-- comment_wide -->

<!-- # 로그 오즈비 구하기 -->
<!-- comment_wide <- comment_wide %>% -->
<!--   mutate(log_odds_ratio = log(((pos + 1) / (sum(pos + 1))) / -->
<!--                               ((neg + 1) / (sum(neg + 1))))) -->

<!-- comment_wide -->
<!-- ``` -->


<!-- #### 2. 로그 오즈비가 가장 큰 단어 10개씩 추출하기 -->

<!-- <!-- 긍정 댓글과 부정 댓글에서 로그 오즈비가 가장 큰 단어를 10개씩 추출하겠습니다. 그럼 다음, 로그 오즈비가 0보다 크면 `"pos"`, 그렇지 않으면 `"neg"`로 분류하고, 결과를 보기 편하게 로그 오즈비 기준으로 내림차순 정렬하겠습니다. 출력 결과를 살펴보면 긍정 댓글과 부정 댓글에 상대적으로 어떤 단어가 더 많이 사용됐는지 알 수 있습니다. --> -->

<!-- <!-- ```{r} --> -->
<!-- <!-- top10 <- comment_wide %>% --> -->
<!-- <!--   filter(rank(log_odds_ratio) <= 10 | rank(-log_odds_ratio) <= 10) %>% --> -->
<!-- <!--   mutate(sentiment = ifelse(log_odds_ratio > 0, "pos", "neg")) %>% --> -->
<!-- <!--   arrange(-log_odds_ratio) --> -->

<!-- <!-- top10 %>% print(n = Inf) --> -->
<!-- <!-- ``` --> -->


<!-- 긍정 댓글과 부정 댓글에서 로그 오즈비가 가장 큰 단어를 10개씩 추출하겠습니다. 먼저 `log_odds_ratio`가 `0`보다 크면 `"pos"`, 그렇지 않으면 `"neg"`로 분류한 다음, `log_odds_ratio`의 절대값이 가장 높은 단어를 10개씩 추출하겠습니다. 출력 결과를 보면 긍정 댓글과 부정 댓글에 상대적으로 어떤 단어가 더 많이 사용됐는지 알 수 있습니다. -->

<!-- ```{r} -->
<!-- top10 <- comment_wide %>% -->
<!--   group_by(sentiment = ifelse(log_odds_ratio > 0, "pos", "neg")) %>% -->
<!--   slice_max(abs(log_odds_ratio), n = 10) -->
<!-- ``` -->

<!-- ```{r eval=F} -->
<!-- top10 %>% print(n = Inf) -->
<!-- ``` -->

<!-- ```{r echo=F} -->
<!-- top10 %>% print(n = 10) -->
<!-- ``` -->

<!-- #### 로그 오즈비가 동점인 단어는 제외하고 추출하기 -->

<!-- `top10` 출력 결과의 `A tibble: 30 x 5`를 보면 `top10`이 30행으로 구성됨을 알 수 있습니다. 긍정 댓글과 부정 댓글에서 로그 오즈비가 가장 큰 단어를 10개씩 추출했는데 20행이 아니라 30행인 이유는  -->
<!-- 부정 댓글에서 `log_odds_ratio`가 동점인 단어가 모두 추출됐기 때문입니다. `slice_max()`에 `with_ties = F`를 입력해 동점을 제외하고 로그 오즈비가 가장 큰 단어를 10개씩 추출하겠습니다. 출력 결과의 `A tibble: 20 x 5`를 보면 20개의 단어가 추출됐음을 알 수 있습니다. -->

<!-- ```{r} -->
<!-- top10 <- comment_wide %>% -->
<!--   group_by(sentiment = ifelse(log_odds_ratio > 0, "pos", "neg")) %>% -->
<!--   slice_max(abs(log_odds_ratio), n = 10, with_ties = F) -->
<!-- ``` -->

<!-- ```{r eval=F} -->
<!-- top10 %>% print(n = Inf) -->
<!-- ``` -->

<!-- ```{r echo=F} -->
<!-- top10 %>% print(n = 10) -->
<!-- ``` -->


<!-- #### 3. 막대 그래프 만들기 -->

<!-- 로그 오즈비를 이용해 막대 그래프를 만들겠습니다. 출력된 그래프를 보면 긍정 댓글과 부정 댓글에 상대적으로 어떤 단어가 많이 사용되었는지 알 수 있습니다. -->

<!-- ```{r} -->
<!-- # 막대 그래프 만들기 -->
<!-- ggplot(top10, aes(x = reorder(word, log_odds_ratio), -->
<!--                       y = log_odds_ratio, -->
<!--                       fill = sentiment)) + -->
<!--   geom_col() + -->
<!--   coord_flip() + -->
<!--   labs(x = NULL) + -->
<!--   theme(text = element_text(family = "nanumgothic")) -->
<!-- ``` -->



<!-- <!-- #### 로그 오즈비가 동점인 단어는 제외하고 추출하기 - `rank(ties.method = "first")` --> -->

<!-- <!-- `top10` 출력 결과의 `A tibble: 19 x 5`를 보면 `top10`이 19행으로 구성됨을 알 수 있습니다. 긍정 댓글과 부정 댓글에서 로그 오즈비가 가장 큰 단어를 10개씩 추출했는데 20행이 아니라 19행인 이유는 부정 댓글의 단어가 9개만 추출됐기 때문입니다. `sentiment`가 `"neg"인 행을 추출하면 10 행이 아니라 8행임을 알 수 있습니다. --> -->

<!-- <!-- ```{r} --> -->
<!-- <!-- top10 %>% --> -->
<!-- <!--   filter(sentiment == "neg") --> -->
<!-- <!-- ``` --> -->

<!-- <!-- 이는 `rank()`의 동점 처리 방식 때문에 생긴 현상입니다. 순위를 나타낸 변수를 여러가지 방식으로 만든 다음 차이를 살펴보겠습니다. --> -->

<!-- <!-- ```{r} --> -->
<!-- <!-- comment_wide %>% --> -->
<!-- <!--   arrange(log_odds_ratio) %>% --> -->
<!-- <!--   mutate(num_row = row_number(),                       # 행 순서 --> -->
<!-- <!--          num_rank = rank(log_odds_ratio),              # 동점시 평균 --> -->
<!-- <!--          num_rank2 = rank(log_odds_ratio,              # 동점시 행 순서 --> -->
<!-- <!--                           ties.method = "first")) %>% --> -->
<!-- <!--   select(-pos, -neg) %>% --> -->
<!-- <!--   head(10) --> -->
<!-- <!-- ``` --> -->

<!-- <!-- `rank()`는 값이 동일한 행이 여럿이면 행 순서 값을 평균해서 순위를 구합니다. 앞 코드의 출력 결과에서 `num_rank`를 보면 `"못한"`과 `"미친"`의 값이 `3.5`입니다. 이는 `"못한"`과 `"미친"`의 `log_odds_ratio`가 동점이므로 행 순서 값`3`과 `4`를 평균한 것입니다. 마찬가지로 `"가난한"`, `"모르는"`, `"아쉽다"`의 `num_rank`도 행 순서 값 `6`, `7`, `8`을 평균한 `8` 입니다. 따라서 `rank()`로 순위를 구하면 9행 까지는 `8`이하이고 10행부터는 `15` 이상이므로 `filter()`로 순위 값 `10` 이하를 추출하면 9번째 행 까지만 남게 되는 것입니다. --> -->

<!-- <!-- 이 문제를 피하려면 동점일 때 행 순서 값을 부여하도록 `rank()`에 `ties.method = "first"`를 입력하면 됩니다. `num_rank2`를 보면 `log_odds_ratio`가 같을 때 행 순서대로 순위가 부여된 것을 알 수 있습니다. --> -->


<!-- <!-- #### 동점을 제외하고 로그 오즈비가 가장 큰 단어 10개씩 추출하기 --> -->

<!-- <!-- 긍정 댓글과 부정 댓글에서 동점을 제외하고 로그 오즈비가 가장 큰 단어 10개씩 추출하겠습니다. 출력 결과의 `A tibble: 20 x 5`를 보면 기대한 대로 20개의 단어가 추출됐음을 알 수 있습니다. --> -->

<!-- <!-- ```{r} --> -->
<!-- <!-- top10 <- comment_wide %>% --> -->
<!-- <!--   filter(rank(log_odds_ratio, ties.method = "first") <= 10 | --> -->
<!-- <!--          rank(-log_odds_ratio, ties.method = "first") <= 10) %>% --> -->
<!-- <!--   mutate(sentiment = ifelse(log_odds_ratio > 0, "pos", "neg")) %>% --> -->
<!-- <!--   arrange(-log_odds_ratio) --> -->

<!-- <!-- top10 --> -->
<!-- <!-- ``` --> -->


<!-- ## 4.4 감정 사전 수정하여 활용하기 -->

<!-- 앞 절의 출력 결과를 보면 `"소름"`, `"미친"`과 같은 단어가 상대적으로 부정 댓글에 더 많이 사용되었음을 알 수 있습니다. 그런데 이런 단어들은 부정적인 표현이라고 단정하기 어렵습니다. 긍정적인 감정을 극적으로 표현할 때도 사용할 수 있기 때문입니다. -->

<!-- #### 감정 단어 살펴보기 -->

<!-- 댓글 원문을 살펴보면 이 단어들이 주로 긍정적인 의미로 사용되었음을 알 수 있습니다. -->

<!-- ```{r} -->
<!-- # "소름"이 사용된 댓글 -->
<!-- score_comment %>% -->
<!--   filter(str_detect(reply, "소름")) %>% -->
<!--   select(reply) -->

<!-- # "미친"이 사용된 댓글 -->
<!-- score_comment %>% -->
<!--   filter(str_detect(reply, "미친")) %>% -->
<!--   select(reply) -->
<!-- ``` -->

<!-- 이 문제는 긍정적인 의미로 사용된 단어가 감정 사전에 부정적인 단어로 분류되어 있어서 생긴 것입니다. 감정 사전 `dic`을 살펴보면 이 단어들의 감정 점수가 모두 음수로 되어있습니다. -->

<!-- ```{r} -->
<!-- dic %>% filter(word %in% c("소름", "소름이", "미친")) -->
<!-- ``` -->

<!-- 감정 분석은 감정 사전에 의존하기 때문에, 텍스트의 맥락이 감정 사전의 맥락과 다르면 이처럼 반대되는 감정 점수를 부여하는 오류가 발생 합니다. 이럴 때는 감정 사전을 수정해서 활용해야 보다 정확하게 분석할 수 있습니다. -->

<!-- ### 4.4.1 감정 사전 수정하기 -->

<!-- 감정 사전을 수정해서 분석에 활용해 보겠습니다. 지금까지 사용한 'KNU 한국어 감성사전' 원본 `dic`에서 `"소름이"`, `"소름"`, `"미친"`의 `polarity`를 양수 `2`로 수정해 새 감정 사전을 만들겠습니다. -->

<!-- ```{r} -->
<!-- new_dic <- dic %>% -->
<!--   mutate(polarity = ifelse(word %in% c("소름", "소름이", "미친"), 2, polarity)) -->

<!-- new_dic %>% filter(word %in% c("소름", "소름이", "미친")) -->
<!-- ``` -->


<!-- ### 4.4.2 수정한 사전으로 감정 점수 부여하기 -->

<!-- 이제 수정한 감정 사전을 활용해 댓글을 다시 분석하겠습니다. 댓글을 단어 기준으로 토큰화한 `word_comment`에서 앞에서 생성한 감정 점수 `polarity`를 제거하겠습니다. 그런 다음, 새로 만든 감정 사전을 이용해 감정 점수를 부여하고, `NA`를 `0`으로 변환하겠습니다. -->

<!-- ```{r} -->
<!-- new_word_comment <- word_comment %>% -->
<!--   select(-polarity) %>% -->
<!--   left_join(new_dic, by = "word") %>% -->
<!--   mutate(polarity = ifelse(is.na(polarity), 0, polarity)) -->
<!-- ``` -->


<!-- ### 4.4.3 댓글별 감정 점수 구하기 -->

<!-- 단어에 감정 점수를 새로 부여했으니 댓글별로 감정 점수를 합산하겠습니다. 그런 다음 이후 분석 작업은 그룹별로 처리하지 않도록 `ungroup()`으로 그룹을 해제하겠습니다. 출력 결과를 보면 댓글별로 감정 점수가 부여되었음을 알 수 있습니다. -->

<!-- ```{r} -->
<!-- new_score_comment <- new_word_comment %>% -->
<!--   group_by(id, reply) %>% -->
<!--   summarise(score = sum(polarity)) %>% -->
<!--   ungroup() -->

<!-- new_score_comment %>% -->
<!--   select(score, reply) %>% -->
<!--   arrange(-score) -->
<!-- ``` -->


<!-- ### 4.4.4 전반적인 감정 경향 살펴보기 -->

<!-- 댓글의 전반적인 감정 경향을 분석하겠습니다. -->

<!-- #### 1. 감정 분류하기 -->

<!-- 먼저 `score`를 기준으로 1 이상이면 `pos`(긍정), -1 이하면 `neg`(부정), 그 외에는 `neu`(중립)으로 분류하겠습니다. -->

<!-- ```{r} -->
<!-- # 1점 기준으로 긍정 중립 부정 분류 -->
<!-- new_score_comment <- new_score_comment %>% -->
<!--   mutate(sentiment = ifelse(score >=  1, "pos", -->
<!--                      ifelse(score <= -1, "neg", "neu"))) -->
<!-- ``` -->

<!-- #### 2. 감정 분류별 빈도와 비율 구하기 -->

<!-- `sentiment`별 빈도와 비율을 구해 전반적인 경향을 살펴보겠습니다. 원본 감정 사전을 활용했을 때와 비교해 보면, 부정 댓글 `"neg"`의 비중이 10.5%에서 8.87%로 줄어들고, 긍정 댓글 `"pos"`의 비중이 19.5%에서 21.3%로 늘어났습니다. -->

<!-- ```{r} -->
<!-- # 원본 감정 사전 활용 -->
<!-- score_comment %>% -->
<!--   count(sentiment) %>% -->
<!--   mutate(ratio = n/sum(n)*100) -->
<!-- ``` -->

<!-- <br>  -->

<!-- ```{r} -->
<!-- # 수정한 감정 사전 활용 -->
<!-- new_score_comment %>% -->
<!--   count(sentiment) %>% -->
<!--   mutate(ratio = n/sum(n)*100) -->
<!-- ``` -->

<!-- > [편집] 2단 편집 -->

<!-- #### 감정 분류 결과 비교하기 -->

<!-- 감정 분류 비율이 달라진 이유는 `"소름"`, `"소름이"`, `"미친"`이 사용된 여러 댓글이 수정한 사전을 통해 긍정 댓글로 분류되었기 때문입니다. 다음 코드의 출력 결과를 보면 이 단어를 사용한 댓글의 감정 범주 빈도가 달라졌음을 알 수 있습니다. -->
<!-- ```{r} -->
<!-- word <- "소름|소름이|미친" -->

<!-- # 원본 감정 사전 활용 -->
<!-- score_comment %>% -->
<!--   filter(str_detect(reply, word)) %>% -->
<!--   count(sentiment) -->
<!-- ``` -->

<!-- <br> -->

<!-- ```{r} -->
<!-- # 수정한 감정 사전 활용 -->
<!-- new_score_comment %>% -->
<!--   filter(str_detect(reply, word)) %>% -->
<!--   count(sentiment) -->
<!-- ``` -->

<!-- > [편집] 2단 편집 -->

<!-- > [참고] `str_detect()`에 여러 문자를 입력할 때는 `|`로 구분해야 합니다. `|`는 '또는'을 의미하는 정규 표현식 입니다. -->

<!-- <br> -->

<!-- > [참고] 수정한 사전을 사용하더라도 댓글에 사용된 다른 단어들의 감정 점수가 낮으면 부정 댓글로 분류될 수 있습니다. -->


<!-- --- -->

<!-- > [알아두면 좋아요] 신조어에 감정 점수를 부여하는 방법 -->

<!-- 감정 분석은 사전에 기반하기 때문에 '쩐다', '핵노잼'과 같이 사전에 없는 신조어에는 감정 점수가 부여되지 않는 한계가 있습니다. 다음 코드의 출력 결과를 보면 두 문장 모두 점수가 부여되지 않습니다. -->

<!-- ```{r} -->
<!-- df <- tibble(sentence = c("이번 에피소드 쩐다",  -->
<!--                           "이 영화 핵노잼")) %>%  -->
<!--   unnest_tokens(input = sentence,  -->
<!--                 output = word,  -->
<!--                 token = "words",  -->
<!--                 drop = F) -->

<!-- df %>%  -->
<!--   left_join(dic, by = "word") %>% -->
<!--   mutate(polarity = ifelse(is.na(polarity), 0, polarity)) %>%  -->
<!--   group_by(sentence) %>%  -->
<!--   summarise(score = sum(polarity)) -->
<!-- ``` -->

<!-- 다음과 같이 감정 사전에 신조어와 감정 점수를 추가하면 신조어에도 감정 점수를 부여할 수 있습니다. -->

<!-- ```{r} -->
<!-- # 신조어 목록 생성 -->
<!-- newword <- tibble(word = c("쩐다", "핵노잼"),  -->
<!--                   polarity = c(2, -2)) -->

<!-- # 사전에 신조어 추가 -->
<!-- newword_dic <- bind_rows(dic, newword) -->

<!-- # 새 사전으로 감정 점수 부여 -->
<!-- df %>%  -->
<!--   left_join(newword_dic, by = "word") %>% -->
<!--   mutate(polarity = ifelse(is.na(polarity), 0, polarity)) %>%  -->
<!--   group_by(sentence) %>%  -->
<!--   summarise(score = sum(polarity)) -->

<!-- ``` -->

<!-- 어떤 신조어를 사전에 추가할지 모르겠다면 감정 점수가 부여되지 않은 단어 중에 사용 빈도가 높은 단어를 살펴보면 도움이 됩니다. 빈도가 높은 단어 중에 감정을 표현하는 단어가 있다면 점수를 부여해 사전에 추가하면 됩니다. -->

<!-- --- -->


<!-- ### 4.4.5 감정 분류별 주요 단어 살펴보기 -->

<!-- 수정한 감정 사전을 이용해 댓글별 감정 점수를 다시 구했으니 주요 단어도 다시 살펴봐야 합니다. 단어 로그 오즈비를 새로 구해 긍정 댓글과 부정 댓글에서 상대적으로 많이 사용된 단어가 무엇인지 살펴보겠습니다. -->


<!-- #### 1. 두 글자 이상 한글 단어만 남기고 단어 빈도 구하기 -->

<!-- 문장별 감정 점수가 부여된 `new_score_comment`를 단어 기준으로 토큰화하고 두 글자 이상의 한글 단어만 남기겠습니다. 그런 다음, `sentiment`별 `word`의 빈도를 구하겠습니다. -->

<!-- ```{r} -->
<!-- # 토큰화 및 전처리 -->
<!-- new_comment <- new_score_comment %>% -->
<!--   unnest_tokens(input = reply, -->
<!--                 output = word, -->
<!--                 token = "words", -->
<!--                 drop = F) %>% -->
<!--   filter(str_detect(word, "[가-힣]") & -->
<!--            str_count(word) >= 2) -->

<!-- # 감정 및 단어별 빈도 구하기 -->
<!-- new_frequency_word <- new_comment %>% -->
<!--   count(sentiment, word, sort = T) -->
<!-- ``` -->

<!-- #### 2. 로그 오즈비 구하기 -->

<!-- 감정 및 단어별 빈도가 담긴 `new_frequency_word`를 Wide form으로 변환한 뒤 로그 오즈비를 구하겠습니다. -->
<!-- ```{r} -->
<!-- # Wide form으로 변환 -->
<!-- new_comment_wide <- new_frequency_word %>% -->
<!--   filter(sentiment != "neu") %>% -->
<!--   pivot_wider(names_from = sentiment, -->
<!--               values_from = n, -->
<!--               values_fill = list(n = 0)) -->

<!-- # 로그 오즈비 구하기 -->
<!-- new_comment_wide <- new_comment_wide %>% -->
<!--   mutate(log_odds_ratio = log(((pos + 1) / (sum(pos + 1))) / -->
<!--                               ((neg + 1) / (sum(neg + 1))))) -->
<!-- ``` -->


<!-- #### 3. 로그 오즈비가 큰 단어로 막대 그래프 만들기 -->

<!-- <!-- 긍정 댓글과 부정 댓글에서 로그 오즈비가 가장 큰 단어를 10개씩 추출하겠습니다. `rank()`로 순위를 구할 때 동점을 제외하도록 `ties.method = "first"`를 입력하겠습니다. 로그 오즈비가 `0`보다 크면 `"pos"`, 그렇지 않으면 `"neg"`로 분류하고, 결과를 보기 편하게 로그 오즈비 기준으로 내림차순 정렬하겠습니다. 마지막으로 막대 그래프를 만들어 긍정 댓글과 부정 댓글에서 상대적으로 많이 사용된 단어를 비교하겠습니다. --> -->

<!-- <!-- ```{r} --> -->
<!-- <!-- new_top10 <- new_comment_wide %>% --> -->
<!-- <!--   filter(rank(log_odds_ratio, ties.method = "first") <= 10 | --> -->
<!-- <!--          rank(-log_odds_ratio, ties.method = "first") <= 10) %>% --> -->
<!-- <!--   mutate(sentiment = ifelse(log_odds_ratio > 0, "pos", "neg")) %>% --> -->
<!-- <!--   arrange(-log_odds_ratio) --> -->

<!-- <!-- # 막대 그래프 만들기 --> -->
<!-- <!-- ggplot(new_top10, aes(x = reorder(word, log_odds_ratio), --> -->
<!-- <!--                       y = log_odds_ratio, --> -->
<!-- <!--                       fill = sentiment)) + --> -->
<!-- <!--   geom_col() + --> -->
<!-- <!--   coord_flip() + --> -->
<!-- <!--   labs(x = NULL) --> -->

<!-- <!-- ``` --> -->

<!-- 긍정 댓글과 부정 댓글에서 로그 오즈비가 가장 큰 단어를 10개씩 추출한 다음, 막대 그래프를 만들어 상대적으로 많이 사용된 단어를 비교하겠습니다. -->

<!-- ```{r} -->
<!-- new_top10 <- new_comment_wide %>% -->
<!--   group_by(sentiment = ifelse(log_odds_ratio > 0, "pos", "neg")) %>% -->
<!--   slice_max(abs(log_odds_ratio), n = 10, with_ties = F) -->

<!-- # 막대 그래프 만들기 -->
<!-- ggplot(new_top10, aes(x = reorder(word, log_odds_ratio), -->
<!--                       y = log_odds_ratio, -->
<!--                       fill = sentiment)) + -->
<!--   geom_col() + -->
<!--   coord_flip() + -->
<!--   labs(x = NULL) + -->
<!--   theme(text = element_text(family = "nanumgothic")) -->
<!-- ``` -->


<!-- #### 분석 결과 비교히기 -->

<!-- 분석 결과를 원본 감정 사전을 활용했을 때와 비교해 보겠습니다. `new_top10` 출력 결과를 보면 원본 감정 사전을 사용했을 때와 달리 `"소름"`이 긍정 댓글에서 자주 사용한 단어로 추출되고, `"미친"`은 목록에서 사라졌음을 알 수 있습니다. -->

<!-- ```{r } -->
<!-- # 원본 감정 사전 활용 -->
<!-- top10 %>%  -->
<!--   select(-pos, -neg) %>%  -->
<!--   arrange(-log_odds_ratio) %>%  -->
<!--   print(n = Inf) -->
<!-- ``` -->


<!-- <br> -->

<!-- ```{r } -->
<!-- # 수정한 감정 사전 활용 -->
<!-- new_top10 %>% -->
<!--   select(-pos, -neg) %>% -->
<!--   arrange(-log_odds_ratio) %>% -->
<!--   print(n = Inf) -->
<!-- ``` -->

<!-- > [편집] 2단 편집, 박스로 강조 "3 소름 3.76 pos" -->

<!-- `"미친"`이 목록에서 사라진 이유는 로그 오즈비가 10권 안에 들지 못할 정도로 낮기 때문입니다. 다음 코드의 출력 결과를 보면 `"미친"`의 로그 오즈비는 1.80입니다. `new_top10`에서 긍정 단어 10위인 `"최고의"`의 로그 오즈비가 2.90이므로 `"미친"`이 목록에 포함되지 않는 것입니다. -->
<!-- ```{r} -->
<!-- new_comment_wide %>% -->
<!--   filter(word == "미친") -->
<!-- ``` -->


<!-- #### 4. 주요 단어가 사용된 댓글 살펴보기 -->

<!-- 긍정 댓글과 부정 댓글에서 상대적으로 자주 사용된 단어가 무엇인지 확인했으니, 단어가 사용된 댓글을 추출해 살펴보겠습니다. 코드의 출력 결과를 보면 긍정 댓글은 수상을 축하하고 대한민국의 위상이 올라갔다는 내용이 주를 이루는 반면, 부정 댓글은 시상 자체보다는 감독의 정치 성향이나 다른 사용자의 정치 성향을 비판하는 내용이 주를 이루고 있음을 알 수 있습니다. -->

<!-- ```{r eval=F} -->
<!-- # 긍정 댓글 원문 -->
<!-- new_score_comment %>% -->
<!--   filter(sentiment == "pos" & str_detect(reply, "축하")) %>% -->
<!--   select(reply) -->
<!-- ``` -->

<!-- ```{r echo=F} -->
<!-- # 긍정 댓글 원문 -->
<!-- new_score_comment %>% -->
<!--   filter(sentiment == "pos" & str_detect(reply, "축하")) %>% -->
<!--   select(reply) %>% -->
<!--   print(n = 3) -->
<!-- ``` -->

<!-- <br> -->

<!-- ```{r eval=F} -->
<!-- new_score_comment %>% -->
<!--   filter(sentiment == "pos" & str_detect(reply, "소름")) %>% -->
<!--   select(reply) -->
<!-- ``` -->

<!-- ```{r echo=F} -->
<!-- new_score_comment %>% -->
<!--   filter(sentiment == "pos" & str_detect(reply, "소름")) %>% -->
<!--   select(reply)%>% -->
<!--   print(n = 3) -->
<!-- ``` -->

<!-- <br> -->

<!-- ```{r eval=F} -->
<!-- # 부정 댓글 원문 -->
<!-- new_score_comment %>% -->
<!--   filter(sentiment == "neg" & str_detect(reply, "좌빨")) %>% -->
<!--   select(reply) -->
<!-- ``` -->

<!-- ```{r echo=F} -->
<!-- # 부정 댓글 원문 -->
<!-- new_score_comment %>% -->
<!--   filter(sentiment == "neg" & str_detect(reply, "좌빨")) %>% -->
<!--   select(reply) %>% -->
<!--   print(n = 3) -->
<!-- ``` -->

<!-- <br> -->

<!-- ```{r eval=F} -->
<!-- new_score_comment %>% -->
<!--   filter(sentiment == "neg" & str_detect(reply, "못한")) %>% -->
<!--   select(reply) -->
<!-- ``` -->


<!-- ```{r echo=F} -->
<!-- new_score_comment %>% -->
<!--   filter(sentiment == "neg" & str_detect(reply, "못한")) %>% -->
<!--   select(reply) %>% -->
<!--   print(n = 3) -->
<!-- ``` -->



<!-- > [알아두면 좋아요] 단어의 감정 점수는 신중하게 정해야 합니다. -->

<!-- > 같은 단어도 맥락에 따라 표현하는 감정이 다르기 때문에 단어의 감정 점수는 신중하게 정해야 합니다. '빠르다'라는 단어로 예를 들어 보겠습니다. 만약 '빠르다'가 스마트폰 사용 후기에 사용됐다면 속도가 빠르다는 의미일 테니 긍정적인 감정을 표현한다고 할 수 있습니다. 하지만 동영상 강의 관련 댓글에 사용됐다면 강의 진행 속도나 강사의 말이 빠르다는 의미 일테니 부정적인 감정을 표현한다고 볼 수 있습니다. 이처럼 같은 단어라도 표현하는 감정이 다를 수 있기 때문에 분석하는 텍스트의 맥락에 맞게 감정 점수를 정해야만 정확하게 분석 할 수 있습니다. -->


